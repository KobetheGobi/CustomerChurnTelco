import pandas as pd
import numpy as np

# Telco Customer Churn dataset
np.random.seed(42)
n_samples = 1000
customerID = [f'C{i:04d}' for i in range(n_samples)]
gender = np.random.choice(['Male', 'Female'], n_samples)
SeniorCitizen = np.random.choice([0, 1], n_samples)
Partner = np.random.choice(['Yes', 'No'], n_samples)
Dependents = np.random.choice(['Yes', 'No'], n_samples)
tenure = np.random.randint(1, 73, n_samples)
PhoneService = np.random.choice(['Yes', 'No'], n_samples)
MultipleLines = np.random.choice(['Yes', 'No', 'No phone service'], n_samples)
InternetService = np.random.choice(['DSL', 'Fiber optic', 'No'], n_samples)
OnlineSecurity = np.random.choice(['Yes', 'No', 'No internet service'], n_samples)
OnlineBackup = np.random.choice(['Yes', 'No', 'No internet service'], n_samples)
DeviceProtection = np.random.choice(['Yes', 'No', 'No internet service'], n_samples)
TechSupport = np.random.choice(['Yes', 'No', 'No internet service'], n_samples)
StreamingTV = np.random.choice(['Yes', 'No', 'No internet service'], n_samples)
StreamingMovies = np.random.choice(['Yes', 'No', 'No internet service'], n_samples)
Contract = np.random.choice(['Month-to-month', 'One year', 'Two year'], n_samples)
PaperlessBilling = np.random.choice(['Yes', 'No'], n_samples)
PaymentMethod = np.random.choice(['Electronic check', 'Mailed check', 'Bank transfer (automatic)', 'Credit card (automatic)'], n_samples)
MonthlyCharges = np.round(np.random.uniform(20, 120, n_samples), 2)
TotalCharges = np.round(MonthlyCharges * tenure, 2)
Churn = np.random.choice(['Yes', 'No'], n_samples)

# Create DataFrame
data = pd.DataFrame({
    'customerID': customerID,
    'gender': gender,
    'SeniorCitizen': SeniorCitizen,
    'Partner': Partner,
    'Dependents': Dependents,
    'tenure': tenure,
    'PhoneService': PhoneService,
    'MultipleLines': MultipleLines,
    'InternetService': InternetService,
    'OnlineSecurity': OnlineSecurity,
    'OnlineBackup': OnlineBackup,
    'DeviceProtection': DeviceProtection,
    'TechSupport': TechSupport,
    'StreamingTV': StreamingTV,
    'StreamingMovies': StreamingMovies,
    'Contract': Contract,
    'PaperlessBilling': PaperlessBilling,
    'PaymentMethod': PaymentMethod,
    'MonthlyCharges': MonthlyCharges,
    'TotalCharges': TotalCharges,
    'Churn': Churn
})

data.head()

# Handle missing values (if any)
data['TotalCharges'] = data['TotalCharges'].replace(" ", np.nan).astype(float)
data['TotalCharges'] = data['TotalCharges'].fillna(data['TotalCharges'].mean())

# Detect and handle outliers (simple method using IQR)
Q1 = data['MonthlyCharges'].quantile(0.25)
Q3 = data['MonthlyCharges'].quantile(0.75)
IQR = Q3 - Q1
filter = (data['MonthlyCharges'] >= (Q1 - 1.5 * IQR)) & (data['MonthlyCharges'] <= (Q3 + 1.5 * IQR))
data = data.loc[filter]

# Normalize numerical features
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
data[['tenure', 'MonthlyCharges', 'TotalCharges']] = scaler.fit_transform(data[['tenure', 'MonthlyCharges', 'TotalCharges']])

# Encode categorical features
data = pd.get_dummies(data, columns=['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod', 'Churn'], drop_first=True)


import matplotlib.pyplot as plt
import seaborn as sns

# Plot distributions of numerical features
fig, ax = plt.subplots(1, 3, figsize=(18, 6))
sns.histplot(data['tenure'], bins=20, kde=True, ax=ax[0])
sns.histplot(data['MonthlyCharges'], bins=20, kde=True, ax=ax[1])
sns.histplot(data['TotalCharges'], bins=20, kde=True, ax=ax[2])
ax[0].set_title('Distribution of Tenure')
ax[1].set_title('Distribution of Monthly Charges')
ax[2].set_title('Distribution of Total Charges')
plt.savefig('distribution_plots.png')
plt.show()

# Plot the count of churn
plt.figure(figsize=(6, 4))
sns.countplot(x='Churn_Yes', data=data)
plt.title('Count of Churn')
plt.xlabel('Churn')
plt.ylabel('Count')
plt.savefig('churn_count_plot.png')
plt.show()

# Correlation heatmap
plt.figure(figsize=(14, 10))
sns.heatmap(data.corr(), annot=True, fmt=".2f", cmap='coolwarm')
plt.title('Correlation Heatmap')
plt.savefig('correlation_heatmap.png')
plt.show()


from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report

# Split the data into training and testing sets
X = data.drop(['customerID', 'Churn_Yes'], axis=1)
y = data['Churn_Yes']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train and evaluate models
models = {
    'Logistic Regression': LogisticRegression(max_iter=1000),
    'Random Forest': RandomForestClassifier(n_estimators=100),
    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100)
}

results = {}
for model_name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    results[model_name] = {
        'Accuracy': accuracy_score(y_test, y_pred),
        'Precision': precision_score(y_test, y_pred),
        'Recall': recall_score(y_test, y_pred),
        'F1 Score': f1_score(y_test, y_pred)
    }

# Display results
results_df = pd.DataFrame(results).T
results_df


# Confusion Matrix for the best model (Random Forest in this case)
best_model = models['Random Forest']
y_pred = best_model.predict(X_test)
conf_matrix = confusion_matrix(y_test, y_pred)
plt


